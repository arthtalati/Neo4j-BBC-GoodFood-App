{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scapper_list_of_urls.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/BSge7kYOGb1eJ2MBZlSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthtalati/Neo4j-BBC-GoodFood-App/blob/master/scapper_list_of_urls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "752tyGZxcrge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv7i0RajcwRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scrapy\n",
        "import scrapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bqWdMc6cya0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lxml import html\n",
        "from lxml import etree\n",
        "from bs4 import BeautifulSoup\n",
        "from scrapy.selector import Selector\n",
        "from scrapy.http import HtmlResponse\n",
        "\n",
        "useful_info = []\n",
        "# Enter list of URLS here\n",
        "url_list = [\"https://www.bbcgoodfood.com/recipes/decadent-chocolate-truffle-torte\", \"https://www.bbcgoodfood.com/recipes/spider-biscuits\",\n",
        "            \"https://www.bbcgoodfood.com/recipes/chocolate-spider-cookies\", \"https://www.bbcgoodfood.com/recipes/chocolate-orange-spider-jellies\"]\n",
        "for url in url_list:\n",
        "  driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "  driver.get(url)\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  page = soup.prettify()\n",
        "\n",
        "  json_data = Selector(text = page).xpath('//script/text()')[41].extract()\n",
        "  useful_info.append(json_data)\n",
        "  driver.quit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OYy2A3Wc3la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(4):\n",
        "  print(\"\\n\",i)\n",
        "  print(useful_info[i])\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}